---
title: "Growth at Risk: The Distribution of Future GDP Growth in Israel"
author: "Michael Gurkov and Osnat Zohar"
institute: "Bank of Israel \\newline Research Department"
date: "14 September, 2020"
classoption: t
output:
  beamer_presentation:
    includes:
      in_header: !expr here::here('vignettes/GaR-PresentationPreamble.tex')
    latex_engine: xelatex
    slide_level: 2
bibliography: "GaR.bib"
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, echo = FALSE, message = FALSE,
  warning = FALSE, comment = "#>"
)
```


```{r setup}

devtools::load_all()

setwd(paste0(
  file.path(Sys.getenv("USERPROFILE"),fsep = "\\"),
  "\\Documents\\GaRPackg\\vignettes"))


```


```{r set_plot_params}

theme_set(theme_bw() + 
            theme(title = element_text(size = 20),
                axis.text = element_text(size = 15),
                axis.title = element_text(size = 15),
                strip.text = element_text(size = 15),
                legend.position = "bottom",
                legend.title = element_blank(),
                legend.text = element_text(size = 15)))



```


```{r load_libraries}

library(tidyverse)

library(cowplot)

library(broom)

library(gghighlight)

```


```{r Get_partitions, child="Partition-Specs.Rmd"}

```


```{r import_data, child="GaR-ImportAndProcessData.Rmd"}

```


```{r import_robustness_data,eval=FALSE}

fit_df = read_rds(paste0(
  file.path(Sys.getenv("USERPROFILE"), fsep = "\\"),
  "\\OneDrive - Bank Of",
  " Israel\\Data\\BoI\\GaR_Data\\fit_df.RDS"))

```


```{r Analysis}

current_partition = partitions_list$basic

results = run.GaR.analysis(partitions_list = current_partition,
                   vars_df = df,
                   target_var_name = "GDP",
                   horizon_list = parameters_list$horizon_list,
                   quantile_vec = parameters_list$quantile_vec,
                   pca.align.list = list(
                     Dom_FCI = list(
                       var_name = "Spread_CPI_corp",
                       positive_direction = FALSE),
                     Dom_Macro = list(var_name = "GDP"),
                     Global = list(var_name = "rate_euro"),
                     FinCycle = list(var_name = "Credit")))


```

```{r get_auxilary_data}

pca_list = results$pca

pca_variance = lapply(names(pca_list),
                      function(temp_name){

  data.frame(Name = temp_name,
             Variance = round(pca_list[[temp_name]]$pca$sdev[1] ^ 2 /
                                sum(pca_list[[temp_name]]$pca$sdev ^ 2),3),
             stringsAsFactors = FALSE)



}) %>%
  bind_rows()

plot_names_list = list("Macro","Global","Fin. Conditions",
                       "Fin. Cycle")

names(plot_names_list) = names(pca_list)

coeff_df = map_dfr(names(results$qreg_result),
                  function(temp_name){
                    
                    temp_coeff_df = tidy(results$qreg_result[[temp_name]]) %>% 
                      rename(Partition = term, Coeff = estimate, Quantile = tau) %>% 
                      select(Partition, Coeff, Quantile) %>% 
                      mutate(Horizon = temp_name)

  return(temp_coeff_df)

}) %>% 
  mutate(Horizon = factor(Horizon,
                          levels = unlist(parameters_list$horizon_list))) %>% 
  mutate(Quantile = factor(Quantile,
                           levels = parameters_list$quantile_vec)) %>% 
  filter(!Partition == "(Intercept)") %>% 
  mutate(Partition = str_remove_all(Partition,"_xreg")) %>% 
  left_join(plot_names_list %>% 
  enframe(value = "new_name") %>% 
  mutate(new_name = unlist(new_name)),
  by = c("Partition" = "name")) %>% 
  select(-Partition)
  
my_lab = function(string){
  
  paste0("horizon = ", string)
  
}

```

```{r calculate_gar_contribution}

factors_df = map_dfr(names(results$qreg_result),function(temp_name){
    
    data_mat = results$reg_df %>%
      rename_all(~str_remove_all(.,pattern = "_xreg")) %>%
      select(names(current_partition)) %>%
      as.matrix()
    
    coef_vec = coefficients(results$qreg_result[[temp_name]])[-1,1]
    
    gar_factors_df =  t(t(data_mat) * coef_vec)
    
    gar_factors_df = cbind(Date = results$reg_df$Date,
                           as.data.frame(gar_factors_df)) %>% 
      mutate(Horizon = temp_name)
    
    return(gar_factors_df)
 
                        })

factors_df = factors_df %>% 
  rename(Macro = Dom_Macro) %>% 
  rename(`Fin. Cycle` = FinCycle) %>% 
  rename(`Fin. Conditions` = Dom_FCI) %>% 
  pivot_longer(cols = -c(Date,Horizon), names_to = "partition")
  




```



```{r make_df}

realized_df = df %>%
  filter(Date < as.yearqtr("2020 Q1")) %>%
  select(Date, GDP) %>%
  filter(complete.cases(.)) %>%
  rename(realized = GDP) %>%
  mutate(Forecast_Period = paste(Date - 1, Date, sep = "-")) %>%
  select(-Date) %>%
  select(Forecast_Period, realized) %>%
  as_tibble()

benchmark_df = get.gar.forecast(
  partitions_list = NULL,
  vars_df = df %>% filter(Date < as.yearqtr("2020 Q1")),
  target_var_name = "GDP",
  horizon_list = parameters_list$horizon_list,
  quantile_vec = parameters_list$quantile_vec,
  win_len = 40,
  win_type_expanding = TRUE) %>%
  mutate(Forecast_Period = paste(
    Date + as.numeric(Horizon) * 0.25 - 1,
    Date + as.numeric(Horizon) * 0.25,
    sep = "-"
    )) %>%
  mutate(Horizon = as_factor(Horizon)) %>%
  rename(benchmark = GaR_forecast)

staff_forecast_df = import.staff.forecast(raw_df = raw_df) %>%
  as_tibble() %>%
  rename(prediction = Staff_Forecast)

staff_forecast_df = list(
  name = "Staff",
  partition = list(staff = NA),
  pred_df = staff_forecast_df) %>%
  enframe() %>%
  pivot_wider()

```


```{r GaR_Forecast}

models_df = list(GaR_Forecast = partitions_list$basic,
                 Macro_Forecast = partitions_list$macro) %>%
  enframe(value = "partition")

models_df = models_df %>%
  mutate(pred_df = map(partition,function(temp_part){

      temp_forecast = get.gar.forecast(
        partitions_list = temp_part,
        vars_df = df %>% filter(Date < as.yearqtr("2020 Q1")),
        target_var_name = "GDP",
        horizon_list = parameters_list$horizon_list,
        quantile_vec = parameters_list$quantile_vec,
        pca.align.list = list(
          Dom_FCI = list(var_name = "Spread_CPI_corp",
                         positive_direction = FALSE),
          Dom_Macro = list(var_name = "GDP"),
          Global = list(var_name = "gdp_us"),
          FinCycle = list(var_name = "Credit")
        ),
        win_len = 40,
        win_type_expanding = TRUE)

      temp_forecast = temp_forecast %>%
        filter(complete.cases(.)) %>%
        mutate(Forecast_Period = paste(
          Date + as.numeric(Horizon) * 0.25 - 1,
          Date + as.numeric(Horizon) * 0.25,
          sep = "-"
        )) %>%
        mutate(Horizon = as_factor(Horizon)) %>%
        rename(prediction = GaR_forecast)


      return(temp_forecast)

      }))

models_df = models_df %>%
  rbind(staff_forecast_df)

models_df = models_df %>%
  mutate(realized = map(1:nrow(.),~realized_df)) %>%
  mutate(benchmark = map(1:nrow(.),~benchmark_df))


```


```{r calculate_scores}

models_df = models_df %>%
  mutate(
    r2_score = pmap(.l = list(pred_df,realized, benchmark),
                     .f = function(pred_df,realized, benchmark){
                       temp_score = collect_quantile_r2_score(
                         pred_df = pred_df,
                         realized_df = realized,
                         benchmark_df = benchmark)
                       return(temp_score)
                     })
    ) %>%
  mutate(
    pit_score = pmap(.l = list(pred_df,realized),
                     .f = function(pred_df,realized){
                       temp_score = pred_df %>%
                         inner_join(realized_df,
                                    by = "Forecast_Period") %>%
                         rename(actual_values = realized,
                                predicted_values = prediction) %>%
                         quantile.pit.score()

                       return(temp_score)
                     }))

```

## Motivation

\begin {itemize}
\itemsep3em
	\item
	Assessing risks to future economic activity is essential for making knowledgeable forecasts.
	\item
	An important factor: financial vulnerabilities.
	\item
	We provide a methodological tool for assessing risks to growth in Israel using real and financial variables:

	\vspace{1em}

	\begin{center}
		~
	\begin{beamerboxesrounded}[width=0.75\linewidth]{}
		Given current macro-financial conditions, what is the distribution of
		expected economic growth?
	\end{beamerboxesrounded}
	~
	\end{center}

\end{itemize}











## Motivation

\centering
Quantile Regressions of YoY GDP Growth Four Quarters Ahead

\vspace{3mm}

```{r plot_gdp_credit}

temp_df = df %>%
  select(all_of(c("GDP","Credit"))) %>%
  add_leads_to_target_var(target_var_name = "GDP",
                          leads_vector = 4) %>%
  filter(complete.cases(.))

plot_list = map(list("GDP","Credit"), function(temp_var){

temp_qreq = rq(paste0("GDP_4","~",temp_var),
               tau = c(0.05,0.5,0.95),
               data = temp_df) %>%
  coefficients() %>%
  t() %>%
  as.data.frame() %>%
  rownames_to_column() %>%
  mutate(rowname = str_remove_all(rowname, "tau= ")) %>%
  rename(Quantile = rowname,
         my_int = `(Intercept)`,
         my_slope = !!sym(temp_var))

temp_plot = temp_df %>%
  ggplot(aes(x = !!sym(temp_var),
             y = GDP_4)) +
  geom_point() +
  geom_abline(data = temp_qreq,
              aes(intercept = my_int,
                  slope = my_slope,
                  color = Quantile)) +
  scale_color_manual(values = c("green","black","red")) + 
  scale_x_continuous(
    labels = scales::percent_format(accuracy = 1)) +
  scale_y_continuous(
    labels = scales::percent_format(accuracy = 1)) +
  xlab(paste("YoY", temp_var, "growth")) +
  ylab((paste("YoY GDP growth 4 quarters ahead"))) +
  ggtitle(temp_var) +
  theme(legend.position = "none")

  return(temp_plot)

})

legend_p = get_legend(
  plot_list[[1]] + theme(legend.position = "bottom",
                         legend.title = element_text(size = 15)))

plot_grid(plot_grid(plotlist = plot_list,ncol = 2),
          nrow = 2,
          legend_p, rel_heights = c(1,0.2))

```

## The Growth at Risk (GaR) Approach

\vspace{1em}

* GaR is a linear model of density forecasts
  + Based on quantile regression
  + Parsimonious
  + Easy to interpret

\vspace{1em}

* Proposed by @Adrian2019, operationalized by the IMF [@Prasad2019].

\vspace{1em}

* Applied to:
  + Advanced economies [@Aikman2018;@Alessandri2019]
  + Developing economies [@Komatsuzaki2019; @Bespalova2019]


## Contribution

\vspace{3em}

\begin{itemize}
  \setlength\itemsep{3em}
  \item
  Improve understanding of macro-financial linkages in Israel:
  \begin{itemize}
    \item
    Provide empirical evidence to support macro-financial modeling
    (joint project with IMF)
  \end{itemize}
  \item
  Tools for regular assessment of risks:
  \begin{itemize}
    \item
    5th percentile of forecast
    \item
    State-dependent fan charts
  \end{itemize}
\end{itemize}


## Main Results

\begin{itemize}
\setlength\itemsep{1.5em}
\item
In-sample properties of the predictive distribution:
  \begin{enumerate}
	\item
	\textbf{Symmetric} -- upside and downside risks are balanced.
	\item
	\textbf{Forecast uncertainty} rises when the median forecast decreases.
	\item
	\textbf{``Volatility paradox''} -- an increase in credit or asset prices is correlated with short-term GDP growth, but contributes to long-term downside risks.
  \end{enumerate}
\item
These properties are robust to variable selection.
\item
Out-of-sample forecast performance is impaired.
\end{itemize}






## Outline
\tableofcontents


# Methodology and Data  

## Methodology

\label{methodology}

[@Prasad2019]
\begin{enumerate}
	\item
	\textbf{Partition data:} divide a large number of variables
	into $K$ groups ($K$ small).
	\item
	\textbf{Dimension reduction} to alleviate overfitting:
	\begin{itemize}
		\item
		From each group $k\in\{1,...,K\}$, generate a single
		regressor $x^k_t$
		\item
		Method: first principal component
	\end{itemize}
	\item
	\textbf{Quantile regressions --}
	estimate a forecast equation for each quantile $\tau$
	and horizon $h$:
	$$
	Q^{\tau}_{t,h}=\beta^{\tau}_hX_t+\epsilon^{\tau}_{t,h}
	$$
	
	\vspace{0.5em}
	
	where $ X_t=[1, x^1_t, ... , x^K_t]$
	\vspace{1em}
	\begin{flushright}
		\hyperlink{QuantileReg}{\beamerbutton{quantile reg}}
	\end{flushright}
\end{enumerate}



## Data Partitioning

\label{DataPartitioning}

Sample: 1997Q3-2019Q4
\tiny
\begin{tabularx}{\linewidth}{X |X |X | X}
	Macro 						& Global & Fin.  Conditions & Fin. Cycle\\
	\hline
	& & & \\
	GDP 						& GDP - US, Euro 			& BoI rate 				& credit\\
	& & & \\
	State-of-the-Economy index 	& OECD imports				& TA35 implied vol. 	& house prices \\
	& & & \\
	unemployment gap 			& monetary rate - US, Euro  & ILS-USD implied vol. 	& TA125  \\
	& & & \\
								& S\&P500					& corp. bond spreads &  \\
	& & & \\
								& eurostoxx600				& term-spread 			& \\
	& & & \\
								&  non-energy commodity prices			& US-Israel gov. bond spread &\\
	& & & \\
								& Brent oil price &  & \\
	& & & \\
								& US term spread			&						& \\
	& & & \\
								& VIX						& 						& \\
\end{tabularx}

\vspace{1em}

\flushright

\hyperlink{PcaLoadings}{\beamergotobutton{PCA loadings}}

\vspace{-1em}

\flushleft

\hyperlink{PcaTimeseries}{\beamergotobutton{PCA time-series}}




# Estimation Results 
## $1^{st}$ Principal Components 


\label{PcaTimeseries}


```{r plot_pca_timeseries}

pca_timeseries_plots = lapply(names(pca_list), function(name){

  ggplot(data.frame(x = pca_list[[name]]$time_index,
                  y = pca_list[[name]]$pca_obj$x[,1]),
         aes(x = x, y = y)) +
    geom_line() +
    labs(title = plot_names_list[name], x = "", y = "") +
    scale_x_yearqtr()

  })

plot_grid(plotlist = pca_timeseries_plots, nrow = 2)

```


\vspace{-1em}

\flushleft

\hyperlink{CoeffPanel}{\beamergotobutton{Coefficients Panel}}

\vspace{-1.5em}

\flushright

\hyperlink{DataPartitioning}{\beamergotobutton{Data Partitioning}}




\flushright

\vspace{-2em}

\hyperlink{data_partitioning}{\beamerreturnbutton{Data partitioning}}

## Macro shows cyclical pattern (high growth in the short term, low in the long term) 

\label{MacroCoef}

\label{selected_coeffs}

```{r dom_macro_plot, fig.height=6.5}

ggplot(coeff_df %>%
         filter(new_name == "Macro") %>%
         filter(Horizon %in% c(1,12)),
         aes(x = Quantile, y= Coeff)) +
  geom_col(width = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "blue") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 0.1)) + 
  xlab("Quantile") + ylab("GDP growth (YoY)") + ggtitle("Macro coefficients") + 
  facet_wrap(~ Horizon, labeller = labeller(Horizon = my_lab))



```

\vspace{-1em}

\flushleft

\hyperlink{coeffs_panel}{\beamergotobutton{Coefficients Panel}}


## Fin.Cycle contributes to growth in the short term, and to risks in the long term

```{r fin_cycle_plot, fig.height=6.5}

ggplot(coeff_df %>%
         filter(new_name == "Fin. Cycle") %>%
         filter(Horizon %in% c(1,12)),
         aes(x = Quantile, y= Coeff)) +
  geom_col(width = 0.5) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "blue") +
  scale_y_continuous(labels = scales::percent_format(accuracy = 0.1)) + 
  xlab("Quantile") + ylab("GDP growth (YoY)") + 
  ggtitle("Fin. Cycle coefficients") + 
  facet_wrap(~ Horizon,labeller = labeller(Horizon = my_lab))

```

\vspace{-1em}

\flushleft


\hyperlink{CoeffPanel}{\beamergotobutton{Coefficients Panel}}


## Volatility Paradox

\vspace{-1em}

\begin{block}{\center{Brunnermeir and Sannikov 2014}}
\vspace{0.5em}
	Low risks (which contribute to short-term growth), encourage the
	accumulation of risks in the medium-to-long term.
\end{block}


* Financial Cycle factor is correlated with growth in the short term,
  but also with elevated risks in the long term.

* Mechanisms:


\begin{tikzpicture}
			[nodestyle/.style={rounded rectangle,draw=blue!50,fill=blue!20,thick,
				inner sep=2pt,minimum width=10mm},
			%transition/.style={rectangle,draw=black!50,fill=black!20,thick,
			%	inner sep=0pt,minimum size=4mm}
			greynodestyle/.style={rounded rectangle,draw=black!50,fill=black!20,thick,
				inner sep=2pt,minimum width=10mm}]
			
			%Nodes
			\node       (Risk)          	[nodestyle]							{risk today $\downarrow$};			
			\node  	    (Spreads)       	[nodestyle, right=of Risk,xshift=-2mm]		{ spreads $\downarrow$};
			\node       (AssetPrices)      [nodestyle,above right=of Spreads, yshift=-4mm, xshift=4mm] 	{asset prices $\uparrow$};
			\node       (Debt)      [nodestyle,below right=of Spreads, yshift=4mm, xshift=4mm] 	{ \quad{} debt  $\uparrow$ \quad{ } };
			\node       (FutureRisk)      [nodestyle, right=of Spreads, xshift=35mm] 	{ future risk  $\uparrow$ };
			\node       (FinCyc)      [greynodestyle, below=of Debt, yshift=3mm] 	{ Financial Cycle };
			\node       (FCI)      [greynodestyle, left=of FinCyc, xshift=4mm] 	{ Fin. Cond. };
			
			
			
			
			%Lines
			\draw[->, thick] (Risk.east) -- (Spreads.west) node[midway,above] {};
			\draw[->, thick] (Spreads.east) -- (AssetPrices.west) node[midway,above] {};
			\draw[->, thick] (Spreads.east) -- (Debt.west) node[midway,above] {};
			\draw[->, thick] (AssetPrices.east) -- (FutureRisk.west) node[midway,above] {};
			\draw[->, thick] (Debt.east) -- (FutureRisk.west) node[midway,above] {};
			
			
			%		\onslide<2->				
			%		%Nodes
			%		\node       (FinCyc)        [greynodestyle, below=of Debt]		{financial cycle};
			%		\node  	    (FCI)       	[greynodestyle, left=of FinCyc, xshift=-2mm]		{ FCI };
			%		
			
\end{tikzpicture}

# In-sample Properties of Risks to Growth
## Short-Term Forecast of 5th Percentile More Volatile Than Long-Term Forecast

```{r plot_events_plot}

recessions = read.csv(paste0(
  file.path(Sys.getenv("USERPROFILE"),fsep="\\"),
  "\\OneDrive - Bank Of Israel\\",
  "Data\\BoI\\GaR_Data","\\recessions.csv")) %>%
  mutate(across(c(Start, End), ~as.yearqtr(.)))

events = read.csv(paste0(
  file.path(Sys.getenv("USERPROFILE"),fsep="\\"),
  "\\OneDrive - Bank Of Israel\\",
  "Data\\BoI\\GaR_Data","\\events.csv")) %>%
  mutate(across(c(Start, End), ~as.yearqtr(.)))

predict_df =  data.frame(
  Date = results$reg_df$Date,
  Horizon_1 = predict(results$qreg_result$`1`,
                newdata = results$reg_df)[,1],
  Horizon_12 = predict(results$qreg_result$`12`,
                newdata = results$reg_df)[,1]) %>%
  pivot_longer(cols = -Date,
               names_to = "Horizon",
               values_to = "GaR")

predict_df %>%
ggplot() +
  ylim(c(-0.12,0.08)) +
  geom_point(aes(x = Date, y = GaR, color = Horizon)) +
  geom_line(aes(x = Date, y = GaR, color = Horizon)) +
  geom_rect(data = recessions,
            mapping = aes(xmin = Start, xmax = End,
                          ymin = -Inf, ymax = Inf),
            fill = "lightblue", alpha = 0.5) +
  ylab(NULL) + xlab(NULL) +
  ggtitle("Forecast of 5th Percentile, 1Q and 12Q Ahead") +
  geom_point(data = . %>% filter(Date %in% events$Start),
             aes(x = Date, y = GaR),
           color = "blue") +
  geom_segment(data = . %>%
                 filter(Date %in% events$Start),
               aes(x = Date, y = c(0.0745,0.0745,0.0745,
                                   0.0745,-0.0745,-0.0745),
                   xend = Date, yend = GaR),
               arrow = arrow(length = unit(0.1,"cm")),
               color = "blue") +
  geom_text(data = events,
            mapping = aes(x = Start + 1,
                          y = c(0.08,0.08,-0.08),
                          label = Event),
            color = "blue") + 
  labs(caption = paste0("Notes: Shaded areas depict US and Euro",
                        " recessions (NBER and CEPR recessions)")) + 
  theme(plot.caption = element_text(hjust = 0))


```


## The Global factor contributes to risk identification in the short term, Financial Cycle -- in the long term

```{r plot_factor_decomposition}

factors_df %>%
  filter(Horizon %in% c(1,12)) %>%
  ggplot() +
  geom_col(aes(x = Date, y = value,fill = partition),
           position = "stack") +
  geom_line(data = . %>%
              group_by(Date,Horizon) %>%
              summarise(Total = sum(value),.groups = "drop") %>%
              ungroup(),
            aes(x = Date, y = Total), size = 0.5) +
  facet_wrap(~Horizon,labeller = labeller(Horizon = my_lab), scales = "free") +
  xlab(NULL) + ylab(NULL) +
  ggtitle(paste("Factors contribution to the",
                 "GaR forecast \n (5th percentile)")) +
  scale_fill_viridis_d(option = "plasma")

```

## Forecast Median and Dispersion are Negatively Correlated

```{r plot_median_iqr_scatter}

results %>% 
  calculate_skew_and_iqr() %>% 
  mutate(Horizon = factor(Horizon, levels = c(1,4,8,12))) %>% 
  ggplot(aes(x = IQR, y = q0.50)) + 
  geom_point() + 
  geom_smooth(method = "lm",se = FALSE) + 
  xlab("Inter Quartile Range") + ylab("Median") + 
  facet_free(~Horizon, scales = "free",
             labeller = labeller(Horizon = my_lab)) + 
  theme(axis.text = element_text(size = 8))


```


## Risks to Growth are generally balanced
Contrary to other countries **no evidence of skewed distribution**

```{r plot_skewness_1_quarter, fig.height=3}

results %>%
  calculate_skew_and_iqr() %>%
  filter(Horizon == 1) %>%
  select(Date, Skew) %>%
  ggplot(aes(x = Date, y = Skew)) +
  geom_line() +
  geom_hline(yintercept = c(-0.5,0.5), linetype = "dashed",
             color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(x = "", y = "", title = "Quartile Skewness 1Q Ahead")

```

\pause

Consistent with features of past GDP growth

```{r plot_gdp_growth, fig.height=3}

df %>%
  select(Date,gdp_us, gdp_euro, GDP) %>%
  filter(Date < as.yearqtr("2020 Q1")) %>% 
  rename(US = gdp_us, Euro = gdp_euro, Israel = GDP) %>%
  mutate(across(-Date, ~scale(.,center = TRUE, scale = FALSE))) %>% 
  pivot_longer(-Date) %>%
  ggplot(aes(x = value, fill = name)) +
  geom_density(alpha = 0.5) + 
  scale_x_continuous(labels = scales::percent_format(accuracy = 0.1)) + 
  xlab(NULL) + ylab(NULL) + ggtitle("YoY GDP growth density")

```


# Sensitivity to Variable Selection
## Sub-Sampling Bootstrap Analysis

\vspace{1em}

* Our results might be affected by the set of variables we used
to construct the four factors.

\vspace{1em}

* For robustness, we perform a sub-sampling bootstrap procedure
[@Politis1994]
  + We determine a minimal set of variables to be included
  in each group and go over all the different combinations
  of the other variables.
  
  
  + In each iteration, we estimate a GaR model on the
  implied subset of	variables.

## 5th Percentile Forecast

```{r, cache=TRUE, dev="png"}


gar_plot_df = read_rds(paste0(
  file.path(Sys.getenv("USERPROFILE")),
  "\\OneDrive - Bank Of Israel\\Data\\BoI\\",
  "GaR_Data\\gar_plot_df.RDS"))

gar_plot_df %>% 
  ggplot(aes(x = Date, y = GaR_fitted, group = rowname)) + 
  geom_line() + 
  xlab(NULL) + ylab(NULL) + 
  gghighlight(rowname == 4599,
              calculate_per_facet = TRUE,
              use_direct_label = FALSE,use_group_by = FALSE,
              unhighlighted_params = list(alpha = 0.1)) + 
  facet_wrap(~Horizon, scales = "free", labeller = labeller(Horizon = my_lab),nrow = 2)

```


## "Volatility Paradox"

Financial Cycle coefficients at different quantiles (stacked histograms)

```{r plot_coefs_hist}

coeff_plot_data = read_rds(paste0(
  file.path(Sys.getenv("USERPROFILE"), fsep = "\\"),
  "\\OneDrive - Bank Of Israel\\Data\\",
  "BoI\\GaR_Data\\Old_data\\coeffs_df.RDS"))

coeff_plot_data %>% 
  rename(Quantile = Tau) %>%  
  mutate(Horizon = factor(Horizon, levels = c(1,4,8,12))) %>%  
  ggplot(aes(x = Coeff, fill = Quantile)) + 
  geom_histogram() + 
  geom_vline(xintercept = 0, linetype = "dashed") + 
  xlab(NULL) + ylab(NULL) + 
  facet_wrap(~Horizon,scales = "free",nrow = 2,
             labeller = labeller(Horizon = my_lab)) + 
  theme(legend.title = element_text(size = 15))

```


## Negative Correlation between Median and Dispersion

```{r plot_median_iqr_correlations}

med_iqr_plot_df = read_rds(paste0(
  file.path(Sys.getenv("USERPROFILE")),
  "\\OneDrive - Bank Of Israel\\Data\\BoI\\",
  "GaR_Data\\med_iqr_plot_data.RDS"))
  
med_iqr_plot_df %>% 
  mutate(Horizon = factor(Horizon, c(1,4,8,12))) %>%
  ggplot(aes(x = cor)) +
  geom_histogram() +
  xlab(NULL) + ylab(NULL) +
  ggtitle(paste0("Correlaltion between the median",
                 " and IQR \n of the predictive distribution")) +
  geom_vline(xintercept = 0, color = "blue", linetype = "dashed") +
  facet_wrap(~Horizon, scales = "free_y",
             labeller = labeller(Horizon = my_lab))

```



## Symmetric Distribution

```{r plot_skew_robustness, cache=TRUE,dev="png"}

skew_plot = read_rds(paste0(
  file.path(Sys.getenv("USERPROFILE"), fsep = "\\"),
  "\\OneDrive - Bank Of Israel\\Data\\",
  "BoI\\GaR_Data\\Old_data\\skew_plot.RDS"))

skew_plot +
  ggtitle("Quartile skewness") + 
  facet_wrap(~Horizon,scales = "free",nrow = 2,
             labeller = labeller(Horizon = my_lab)) + 
            theme(title = element_text(size = 20),
                axis.text = element_text(size = 15),
                axis.title = element_text(size = 15),
                strip.text = element_text(size = 15),
                legend.position = "bottom",
                legend.title = element_blank(),
                legend.text = element_text(size = 15))


```


# Out-of-Sample Forecast Performance
## Out-of-Sample Forecast Performance

\vspace{2em}

\begin{itemize}
\setlength\itemsep{2em}
	\item
	GaR model compared to two alternatives:
	\begin{enumerate}
		\item
		Macro only -- partial GaR model without financial variables
		(domestic and global)
		\item
		Staff forecast + DSGE fan chart (symmetric, constant width)
	\end{enumerate}
	\item
	All models evaluated out of sample (expanding window starts at
	40 observations and adds one observation in each step)
\end{itemize}

## Quantile R-Squared
Quantile R-sq. [@Giglio2016] compares forecast performance to a
constant quantile benchmark:

$$
R^2_{\tau,h} \equiv 1- \frac{\sum_{t} \left( y_{t+h} - \hat{Q}^{\tau}_{t,h} \right) \left(\tau - \mathbb{I}_{ \left\{ y_{t+h} - \hat{Q}^{\tau}_{t,h}>0 \right\} } \right) }{ \sum_{t} \left(y_{t+h} - \hat{c}^{\tau}_{t,h} \right) \left(\tau - \mathbb{I}_{ \left\{ y_{t+h} - \hat{Q}^{\tau}_{t,h}>0 \right\} } \right) }
$$

$\hat{Q}^{\tau}_{t,h}$  -- model's forecasts for quantile
$\tau$ at horizon $h$

$\hat{c}^{\tau}_{t,h}$ -- ``constant'' forecast


\begin{itemize}
	\item
	higher values -- better forecast
	\item
	negative values -- model inferior to the constant benchmark
\end{itemize}



## Quantile R-Squared

```{r plot_r2_score}

models_df %>%
  select(name, r2_score) %>%
  unnest(r2_score) %>%
  mutate(name = map_chr(name,~.)) %>%
  mutate(Horizon = factor(Horizon,
                          levels = c("1","4","8","12"))) %>%
  ggplot(aes(x = Quantile, y = score, fill = name)) +
  geom_col(position = "dodge") +
  xlab(NULL) + ylab(NULL) +
  scale_fill_viridis_d(option = "plasma") +
  facet_wrap(~Horizon, labeller = labeller(Horizon = my_lab))

```


## Conclusion

\begin{itemize}
\setlength\itemsep{2em}
  \item
  The Financial Cycle (credit and assets prices) is correlated with higher growth
  in the short term and elevated risks in the long term.
  \item
  Growth distribution in Israel is "balanced" and unskewed
  \item
  Forecast uncertainty rises when the median forecast decreases
  \item
  Future effort will be devoted to development of a forecasting tool
  and extension to other fields (Inflation at Risk)
\end{itemize}


# Appendix {.unlisted .unnumbered}
## Appendix 
## Probability Integral Transform (PIT)
For each quantile $\tau$ and horizon $h$, we compute  the percentage of observations that fall below the forecast quantile $\hat{Q}^{\tau}_{t,h}$:
	$$
	\varphi_{\tau,h} \equiv \frac{1}{T-h} \sum_{t=1}^{T-h} \mathbb{I}_{ \left\{ y_{t+h} <  \hat{Q}^{\tau}_{t,h} \right\} }.
	$$
\begin{itemize}
\setlength\itemsep{1em}
	\item
	A model is better fitted the closer $\varphi_{\tau,h}$ is to
	45-degree line.
	\item
	If the model perfectly fits the empirical  distribution, then
	the fraction of observations falling below quantile $\tau$
	should be exactly $\tau$, namely, $\varphi_{\tau,h}=\tau$.
\end{itemize}

## Probability Integral Transform (PIT)

```{r plot_pit_score}

models_df %>%
  select(name, pit_score) %>%
  unnest(pit_score) %>%
  mutate(name = map_chr(name,~.)) %>%
  mutate(Quantile = as.numeric(Quantile)) %>%
  mutate(Horizon = factor(Horizon,
                          levels = c("1","4","8","12"))) %>%
  ggplot(aes(x = Quantile, y = pit, group = name, color = name)) +
  geom_line() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  xlab(NULL) + ylab(NULL) +
  scale_color_viridis_d(option = "plasma") +
  scale_x_continuous(breaks = c(0.05,0.25,0.5,0.75,0.95),
                   labels = c(0.05,0.25,0.5,0.75,0.95)) +
  facet_wrap(~Horizon,labeller = labeller(Horizon = my_lab))

```


## Quantile Regression 
\label{QuantileReg}

Model: for quantile $\tau$ and horizon $h$, 
$$
Q^{\tau}_{t,h}=\beta^{\tau}_hX_t+\epsilon^{\tau}_{h,t}
$$

$\beta^{\tau}$ is  estimated by solving the minimization problem

$$
\min_{\beta^{\tau}}
\sum_{t=1}^T 
\max \bigg\{
\tau \big( y_{t+h}- \beta^{\tau}X_t \big)
\, ,\,
(\tau-1) \big( y_{t+h}- \beta^{\tau}X_t \big)
\bigg\}
$$

Note: "Quantile crossing" handled using the method of [@Chernozhukov2010]

\begin{flushleft}
\hyperlink{methodology}{\beamergotobutton{Methodology}}
\end{flushleft}
	
	

## 1st PC loadings  

\label{PcaLoadings}

\label{pca_loadings}

```{r plot_pc_loadings}

pca_plots = lapply(names(pca_list), function(name){
  
  pca_var = round(pca_variance$Variance
                  [pca_variance$Name == name] * 100,0)
  
  bar_plot = ggplot(data.frame(Name = names(pca_list[[name]]$pca$rotation[,1]),
                               Val = pca_list[[name]]$pca$rotation[,1]),
                    aes(x = reorder(Name, Val), y = Val)) +
    geom_bar(stat = "identity", width = 0.5) +
    xlab(NULL) + ylab(NULL) + ggtitle(paste0(
    plot_names_list[[name]], " (" ,pca_var, "%)")) +
    coord_flip() + 
    theme(plot.title = element_text(size = 18))
  
  rm(pca_var)
  
  return(bar_plot)
  

})

plot_grid(plotlist = pca_plots)

```

\vspace{-0.5em}

\hyperlink{DataPartitioning}{\beamergotobutton{Data Partitioning}}


## Quantile Regression Coefficients

\label{CoeffPanel}

```{r coeff_panel_plot}

coeff_plot_list = map(unique(coeff_df$Horizon), function(temp_horizon){
  ggplot(coeff_df %>%
           filter(Horizon == temp_horizon),
         aes(x = Quantile, y= Coeff)) +
    geom_col(width = 0.35) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "blue") +
    xlab("Quantile") + ylab(NULL) + ggtitle(paste(temp_horizon, "quarters ahead")) + 
    facet_wrap(~ new_name, scales = "free") + 
    theme(axis.text = element_text(size = 8))
  
})


plot_grid(plotlist = coeff_plot_list)

```


\vspace{-0.5em}

\hyperlink{MacroCoef}{\beamergotobutton{Macro coeff}}


# References {.unlisted .unnumbered}
## References {.allowframebreaks}

<div id="refs"></div>
